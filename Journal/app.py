import streamlit as st
import sqlite3
import pandas as pd

DB_NAME = "my_journal.db"

@st.cache_data 
def load_data():
    try:
        conn = sqlite3.connect(DB_NAME)
        
        query = """
            SELECT 
                title AS "T칤tulo", 
                url AS "URL", 
                source_name AS "Fonte", 
                topic AS "T칩pico", 
                published_at, 
                ID,
                generic_news 
            FROM articles 
            ORDER BY published_at DESC
        """
        # ---------------------
        
        df = pd.read_sql_query(query, conn)
        return df
    except sqlite3.Error as e:
        st.error(f"Ocorreu um erro ao ler o banco de dados: {e}")
        return pd.DataFrame(columns=["T칤tulo", "URL", "Fonte", "T칩pico", "published_at", "ID", "generic_news"])
    finally:
        if 'conn' in locals() and conn:
            conn.close()

st.set_page_config(page_title="MyJournal", layout="wide")
st.title("MyJournal - Arquivo de Not칤cias 游닗")

df = load_data()

if df.empty:
    st.warning("O banco de dados est치 vazio. Execute o script principal de coleta de not칤cias primeiro.")
else:
    st.sidebar.header("Filtros")
    
    all_topics = df['T칩pico'].unique()
    selected_topics = st.sidebar.multiselect("Filtrar por T칩pico:", options=all_topics, default=all_topics)

    all_sources = df['Fonte'].unique()
    selected_sources = st.sidebar.multiselect("Filtrar por Fonte:", options=all_sources, default=all_sources)

    search_title = st.sidebar.text_input("Buscar no T칤tulo:")
    
    df_specific = df[df['generic_news'] == 0] 
    
    df_generic = df[df['generic_news'] == 1]
    
    tab_specific, tab_generic = st.tabs(["Not칤cias Espec칤ficas (RSS)", "Not칤cias Gerais (T칩picos)"])

    with tab_specific:
        st.header("Not칤cias Espec칤ficas (ICL, Meu Tim칚o, etc.)")
        
   
        filtered_df_specific = df_specific[
            df_specific['T칩pico'].isin(selected_topics) &
            df_specific['Fonte'].isin(selected_sources)
        ]
        if search_title:
            filtered_df_specific = filtered_df_specific[filtered_df_specific['T칤tulo'].str.contains(search_title, case=False, na=False)]

 
        st.subheader(f"Exibindo {len(filtered_df_specific)} de {len(df_specific)} artigos espec칤ficos encontrados")
        for index, row in filtered_df_specific.iterrows():
            st.markdown(f"### [{row['T칤tulo']}]({row['URL']})")
            st.write(f"**Fonte:** {row['Fonte']} | **T칩pico:** {row['T칩pico']}")
            st.write(f"**Publicado em:** {row['published_at']}")
            st.divider() 

    with tab_generic:
        st.header("Not칤cias Gerais (Tecnologia, Esportes, etc.)")
        
        filtered_df_generic = df_generic[
            df_generic['T칩pico'].isin(selected_topics) &
            df_generic['Fonte'].isin(selected_sources)
        ]
        if search_title:
            filtered_df_generic = filtered_df_generic[filtered_df_generic['T칤tulo'].str.contains(search_title, case=False, na=False)]

        st.subheader(f"Exibindo {len(filtered_df_generic)} de {len(df_generic)} artigos gerais encontrados")
        for index, row in filtered_df_generic.iterrows():
            st.markdown(f"### [{row['T칤tulo']}]({row['URL']})")
            st.write(f"**Fonte:** {row['Fonte']} | **T칩pico:** {row['T칩pico']}")
            st.write(f"**Publicado em:** {row['published_at']}")
            st.divider()